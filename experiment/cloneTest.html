<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>getUserMedia</title>
    <style>
        video {
            /*opacity: 20%; */
            /*
            height: 720px;
            width: 1280px;
             */
        }
        table, th, td {
            border: 1px solid grey;
            border-collapse: collapse;
            text-align: right;
        }
        td:first-child {
            text-align: left;
        }
    </style>
</head>
<body>
<video id="sourceVid" autoplay playsinline muted controls></video>
<video id="genVid" autoplay playsinline muted controls></video>
<video id="cloneVid" autoplay playsinline muted controls></video>
<br>
<button id="start">Start</button>
<button id="stop">Stop</button>
<button id="clone">Clone</button>
<br>
<label for="apply_constraints_to_generator">Apply Constraints to Generator</label>
<button id="apply_constraints_to_generator" disabled>Apply</button>
<br>
<label for="apply_constraints_to_clone">Apply Constraints to Cloned Generator</label>
<button id="apply_constraints_to_clone">Apply</button>
<br>
<div id="stats"></div>

<script type="module">

    const startBtn = document.querySelector('button#start');
    const stopBtn = document.querySelector('button#stop');
    const stats = document.querySelector('div#stats');
    const cloneBtn = document.querySelector('button#clone');
    const applyBtn = document.querySelector('button#apply_constraints_to_clone');

    const sourceVid = document.querySelector('video#sourceVid');
    const genVid = document.querySelector('video#genVid');
    const cloneVid = document.querySelector('video#cloneVid');


    const sleep = ms => new Promise((resolve) => setTimeout(resolve, ms));

    async function clone(){
        const cloneTrack = genVid.srcObject.getVideoTracks()[0].clone();

        /*
        console.log("cloneTrack:", cloneTrack);
        console.log("cloneTrack settings:", cloneTrack.getSettings());
        console.log("cloneTrack constraints:", cloneTrack.getConstraints());
        console.log("cloneTrack capabilities:", cloneTrack.getCapabilities());
         */

        const cloneStream = new MediaStream([cloneTrack]);

        cloneVid.onloadeddata = (e) => {
            console.log("cloneVid.onloadeddata", e);
            console.log("cloneTrack:", cloneTrack);
            console.log("cloneTrack settings:", cloneTrack.getSettings());
            console.log("cloneTrack constraints:", cloneTrack.getConstraints());
            console.log("cloneTrack capabilities:", cloneTrack.getCapabilities());

            // console.log(`cloned video ${e.target.id}`);
            console.log(`cloned video dimensions ${cloneVid.width}x${cloneVid.height}`);
            console.log(`cloned video offset dimensions ${cloneVid.offsetWidth}x${cloneVid.offsetHeight}`);
            console.log(`cloned video element video dimensions: ${cloneVid.videoWidth}x${cloneVid.videoHeight}`)  ;
        }

        cloneVid.srcObject = cloneStream;
        window.cloneStream = cloneStream;
        console.log("started cloned stream", cloneStream);

        // window.sourceTrack = stream.getVideoTracks()[0];
        window.cloneTrack = cloneTrack;
    }

    async function generatorApplyConstraints(){
        const cloneTrack = cloneVid.srcObject.getVideoTracks()[0];

        // make the video half height
        // LEARNING: no settings to change
        const getCloneSettings = cloneTrack.getSettings();
        console.log("cloneTrack getSettings:", getCloneSettings)
        // const {height, width} = getCloneSettings;

        const genTrack = genVid.srcObject.getVideoTracks()[0];
        const genTrackSettings = genTrack.getSettings();
        const {height, width} = genTrackSettings;
        console.log("genTrack getSettings:", genTrackSettings)

        // FINDING: applyConstraints does not work on cloned generated tracks
        //  solution? Go back to the original track and apply constraints there
        await cloneTrack.applyConstraints({height: height/2, width: width/2})
            .catch(e => console.error("cloneTrack applyConstraints error:", e));
        // await cloneTrack.applyConstraints({frameRate: {ideal: 1}});
    }

    async function generatorCloneApplyConstraints(){
        const cloneTrack = cloneVid.srcObject.getVideoTracks()[0];

        const getCloneSettings = cloneTrack.getSettings();
        console.log("cloneTrack getSettings:", getCloneSettings)
        const {height, width} = getCloneSettings;

        /*
        const genTrack = genVid.srcObject.getVideoTracks()[0];
        const genTrackSettings = genTrack.getSettings();
        const {height, width} = genTrackSettings;
        console.log("genTrack getSettings:", genTrackSettings);
         */

        // FINDING: this SOMETIMES causes a overConstrainted error???
        // ToDo: find out why adding width/2 creates an overconstrained error
        // const constraints = {height: height/2, width: width/2};


        const constraints = {height: height/2, aspectRatio: 1.7777777777777777};
        await cloneTrack.applyConstraints(constraints)
            .catch(e => console.error("cloneTrack applyConstraints error:", e));

        // FINDING: applyConstraints does not work on cloned generated tracks
        //  solution? Go back to the original track and apply constraints there
        const newSettings = cloneTrack.getSettings();
        console.log("cloneTrack getSettings after apply constraints:", newSettings);


    }


    async function generate(stream){
        const canvas = new OffscreenCanvas(1,1);
        const ctx = canvas.getContext('2d', {desynchronized: true}); //('bitmaprenderer');

        const transform = new TransformStream({
            transform: async (frame, controller) => {

                // FINDING:
                //  codedHeight doesn't match displayHeight
                //  ToDo: check this against chrome://media-internals
                /*
                    // console.log(frame);
                    codedHeight: 480
                    codedRect: DOMRectReadOnly {x: 0, y: 0, width: 640, height: 480, top: 0, â€¦}
                    codedWidth: 640
                    colorSpace: VideoColorSpace {primaries: 'bt709', transfer: 'iec61966-2-1', matrix: 'bt709', fullRange: false}
                    displayHeight: 360
                    displayWidth: 640
                    duration: null
                    format: "NV12"
                    timestamp: 33360`
                 */


                // FINDING: need to use displayHeight since codedHeight is wrong
                const height = frame.displayHeight; // frame.codedHeight;
                const width = frame.displayWidth; // frame.codedWidth;
                canvas.height = height;
                canvas.width = width;

                ctx.translate(0, height);
                ctx.scale(1, -1);
                ctx.drawImage(frame, 0, 0);

                // FINDING: timestamp now required
                const params = {
                    timestamp: frame.timestamp,
                    // codedHeight: 640,
                    // codedWidth: 360,
                }
                const newFrame = new VideoFrame(canvas, params);
                await controller.enqueue(newFrame);

                frame.close();

            }
        });


        const [track] = stream.getVideoTracks();
        const {height, width} = track.getSettings();

        const processor = new MediaStreamTrackProcessor(track);
        const reader = processor.readable;

        const generator = new MediaStreamTrackGenerator({kind: track.kind});
        const writer = generator.writable;

        const genStream = new MediaStream([generator]);
        window.genStream = genStream;

        // FINDING: this set the video element to the right size: 640x360
        // genVid.srcObject = stream;

        // This sets it to the wrong size
        //genVid.srcObject = genStream;

        genVid.height = height;
        genVid.width = width;
        genVid.srcObject = genStream;

        // this shrinks the video inside a 640x480 element
        // genVid.height = stream.getVideoTracks()[0].getSettings().height;
        // genVid.width = stream.getVideoTracks()[0].getSettings().width;
        // genVid.srcObject = genStream;

        // This doesn't work - those are getters only
        // genVid.videoHeight = stream.getVideoTracks()[0].getSettings().height;
        // genVid.videoWidth = stream.getVideoTracks()[0].getSettings().width;
        // genVid.srcObject = genStream;

        // console.log(`generated video element dimensions ${genVid.width}x${genVid.height}`);
        // console.log(`generated video offset dimensions ${genVid.offsetWidth}x${genVid.offsetHeight}`);
        // console.log(`generated video element video dimensions ${genVid.videoWidth}x${genVid.videoHeight}`);
        console.log("generator track:", generator);

        // ToDo: check timing here
        // FINDING: These show mostly blank, but work later
        console.log("generator track settings:", generator.getSettings());
        // Always blank
        console.log("generator track constraints:", generator.getConstraints());
        console.log("generator track capabilities:", generator.getCapabilities());

        // FINDING: every new write generating an onplaying event?
        //         genVid.onloadedmetadata = () => {
        genVid.onloadeddata = () => {
            console.log("generator track settings:", generator.getSettings());
            console.log("generator track constraints:", generator.getConstraints());
            console.log("generator track capabilities:", generator.getCapabilities());

            // FINDING: video element is 640x480 when sourceElement is set to 640x360
            // the below didn't help
            // genVid.height = genVid.videoHeight;
            // genVid.width = genVid.videoWidth;
            // genVid.srcObject = genStream;
            console.log(`generated video element dimensions ${genVid.width}x${genVid.height}`);
            console.log(`generated video offset dimensions ${genVid.offsetWidth}x${genVid.offsetHeight}`);
            console.log(`generated video element video dimensions: ${sourceVid.videoWidth}x${sourceVid.videoHeight}`);
        }

        await reader.pipeThrough(transform).pipeTo(writer);

    }

    async function getCam() {
        const stream = await navigator.mediaDevices.getUserMedia({video: {aspectRatio: 1.7777777778}});
        const [track] = stream.getVideoTracks();
        console.log("Source track:", track);
        console.log("Source track settings:", track.getSettings());
        console.log("Source track constraints:", track.getConstraints());
        console.log("Source track capabilities:", track.getCapabilities());

        sourceVid.onloadedmetadata = () => {
            console.log(`video element video dimensions: ${sourceVid.videoWidth}x${sourceVid.videoHeight}`)
        }

        sourceVid.onplaying = async () => {
            console.log("video playing");
            sourceVid.onplaying = null;
            await generate(stream);
        }

        sourceVid.srcObject = stream;
        window.stream = stream;
        console.log("started camera stream")

        window.sourceTrack = stream.getVideoTracks()[0];
    }

    startBtn.onclick = async () => {
        await getCam();
    }

    stopBtn.onclick = () => {
        document.querySelectorAll('video').forEach(vid => vid?.srcObject?.getTracks().forEach(track => track.stop()));
        //stream.getTracks().forEach(track => track.stop());
        console.log("stopped all tracks")
    }

    cloneBtn.onclick = async () => await clone();

    applyBtn.onclick = async () => await generatorCloneApplyConstraints();

    function calculateStats() {

        let decodedFrames = 0,
            droppedFrames = 0,
            startTime = new Date().getTime(),
            initialTime = new Date().getTime();

        const interval = setInterval(function() {

            //see if webkit stats are available; exit if they aren't
            if (!sourceVid.webkitDecodedFrameCount) {
                console.log("Video FPS calcs not supported");
                clearInterval(interval);
            }
            //get the stats
            else {
                const currentTime = new Date().getTime();
                let deltaTime = (currentTime - startTime) / 1000;
                let totalTime = (currentTime - initialTime) / 1000;
                startTime = currentTime;

                // Calculate decoded frames per sec.
                const currentDecodedFPS = (sourceVid.webkitDecodedFrameCount - decodedFrames) / deltaTime;
                const decodedFPSavg = sourceVid.webkitDecodedFrameCount / totalTime;
                decodedFrames = sourceVid.webkitDecodedFrameCount;

                // Calculate dropped frames per sec.
                const currentDroppedFPS = (sourceVid.webkitDroppedFrameCount - droppedFrames) / deltaTime;
                const droppedFPSavg = sourceVid.webkitDroppedFrameCount / totalTime;
                droppedFrames = sourceVid.webkitDroppedFrameCount;

                //write the results to a table
                stats.innerHTML =
                    "<table><tr><th>Type</th><th>Total</th><th>Avg</th><th>Current</th></tr>" +
                    "<tr><td>Decoded</td><td>" + decodedFrames + "</td><td>" + decodedFPSavg.toFixed() + "</td><td>" + currentDecodedFPS.toFixed() + "</td></tr>" +
                    "<tr><td>Dropped</td><td>" + droppedFrames + "</td><td>" + droppedFPSavg.toFixed() + "</td><td>" + currentDroppedFPS.toFixed() + "</td></tr>" +
                    "<tr><td>All</td><td>" + (decodedFrames + droppedFrames) + "</td><td>" + (decodedFPSavg + droppedFPSavg).toFixed() + "</td><td>" + (currentDecodedFPS + currentDroppedFPS).toFixed() + "</td></tr></table>" +
                    "Camera resolution: " + sourceVid.videoWidth + " x " + sourceVid.videoHeight;
            }
        }, 1000);
    }

    sourceVid.addEventListener('loadeddata', (event) => {
        console.log(`Actual stream height: ${sourceVid.videoHeight}`);
        calculateStats();
    });

    // getCam();

</script>
</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>WebCam Framing Analysis Experiment</title>
    <!--script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script-->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"
            crossorigin="anonymous"></script>
    <style>
        div{

        }
        select {
            align-self: center;
            justify-content: center;
            margin: 0 auto;
        }
        .stats {
            display: flex;
            justify-content: center;
        }
        .center{
            text-align: center;
        }
        video {
            position: absolute;
            /*display: flex;*/
            opacity: 50%;
            transform: scaleX(-1);
        }

        canvas {
            /*position: absolute;
            /*display: flex;*/
            z-index: 100;
            /*background-color: black;
            width: 1280px;
            height: 720px;*/
            transform: scaleX(-1);
        }

    </style>
</head>
<body>
<div>
    <div ><!--class="center"-->
    <label for="devices">Choose your camera</label>
    <select name="devices" id="devices"></select>
    </div>
    <br>
    <!-- TODO: replace with a grid -->
    <table > <!--class = "stats"-->
        <tr>
            <td>
                <span id="coords">Coordinates go here</span>
            </td>
            <td>
                <span id="status">Status go here</span>
            </td>
        </tr>
    </table>
</div>
<div class="center">
    <video autoplay playsinline muted></video>
    <canvas></canvas>
</div>


<script type="module">
    const coordSpan = document.querySelector('span#coords');
    const statusSpan = document.querySelector('span#status');
    const deviceSelect = document.querySelector('select#devices');


    const videoElement = document.querySelector('video');
    const canvas = document.querySelector('canvas');
    const ctx = canvas.getContext("2d");

    const VIDEO_HEIGHT = 720;
    const VIDEO_WIDTH = 1280;
    const VIDEO_FPS = 10;

    canvas.height = VIDEO_HEIGHT
    canvas.width = VIDEO_WIDTH
    const w = canvas.width;
    const h = canvas.height;

    const sensitivity = 0.02;

    // for increasing canvas line widths
    const screen_multiplier = parseInt((screen.height / VIDEO_HEIGHT).toFixed(0) );
    // const ctx = canvasElem.getContext("2d");

    let videoDevices = [];

    async function getDevices() {
        let devices = await navigator.mediaDevices.enumerateDevices();
        videoDevices = devices.filter(device => device.kind === 'videoinput');
        console.log("video devices:", videoDevices);
        videoDevices.forEach(device => {
            const option = document.createElement('option');
            option.text = device.label;
            deviceSelect.appendChild(option);
        });
    }

    async function getVideo() {

        // clean up resources if switching sources
        if (window.stream)
            window.stream.getTracks().forEach(track => track.stop());

        let videoSource = videoDevices[deviceSelect.selectedIndex || 3]?.deviceId; // ToDo: save the selected device

        const constraints = {
            video:
                {
                    height: {ideal: VIDEO_HEIGHT},
                    width: {ideal: VIDEO_WIDTH},
                    frameRate: {ideal: VIDEO_FPS},
                    deviceId: videoSource ? {exact: videoSource} : undefined
                }
        };

        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        videoElement.srcObject = stream;

        const settings = stream.getVideoTracks()[0].getSettings();
        console.log(`Capture camera with device ${stream.getVideoTracks()[0].label} at ${settings.width}x${settings.height}`);

        // Insertable streams
        const [track] = stream.getVideoTracks();
        const processor = new MediaStreamTrackProcessor({track});
        const reader = await processor.readable.getReader();

        // const generator = new MediaStreamTrackGenerator({kind: 'video'});
        // outputVideo.srcObject  = new MediaStream([generator]);

        async function readFrame() {
            const {value: frame, done} = await reader.read();
            // value = frame
            if (frame) {
                await faceMesh.send({image: videoElement});
                frame.close();
            }
            if(!done)
                await readFrame();
        }
        await readFrame();


        window.stream = stream;

    }

    const faceMesh = new FaceMesh({
        locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
        }
    });

    faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: false, // not using these
        minDetectionConfidence: 0.8,
        minTrackingConfidence: 0.5
    });

    let maxFaceHeight = 0;

    // Status

    let fromCenter = "unknown";
    let fromEyeLine = "unknown";

    faceMesh.onResults(results => {
        // console.log("faceMesh result:", results)

        // const aspectRatio = (results.image.width / results.image.height).toFixed(1);
        // ctx.save();

        ctx.clearRect(0,0, w, h);
        coordSpan.innerText = "";
        statusSpan.innerText = "";

        if (results.multiFaceLandmarks) {
            for (const landmarks of results.multiFaceLandmarks) {

                function handlePoint(landmark, label){
                    const scaled_x = (landmark.x * ctx.canvas.width).toFixed(0) | 0;
                    const scaled_y = (landmark.y * ctx.canvas.height).toFixed(0) | 0;
                    const scaled_z = (landmark.z * ctx.canvas.width).toFixed(0) | 0;

                    const point = {x: scaled_x, y: scaled_y, z: scaled_z}
                    coordSpan.innerText += `${label}:   x:${point.x} y:${point.y} z:${point.z}\n`;

                    ctx.fillStyle = 'rgba(0, 0, 240, 1)';
                    ctx.strokeStyle = 'rgba(0, 0, 240, 1)';
                    ctx.beginPath();
                    ctx.arc(point.x, point.y, screen_multiplier*2, 0, 2 * Math.PI);
                    ctx.fill();
                    return point
                }


                const center = handlePoint(landmarks[6], "center");
                const top = handlePoint(landmarks[10], "top");
                const bottom = handlePoint(landmarks[152], "bottom");
                // const right = handlePoint(landmarks[234], "right");
                // const left = handlePoint(landmarks[454], "left");

                const rightEar = handlePoint(landmarks[127], "rightEar");
                const leftEar = handlePoint(landmarks[356], "leftEar");


                const dist = Math.hypot(top.x-bottom.x, bottom.y-top.y).toFixed(0);
                maxFaceHeight = dist > maxFaceHeight ? dist: maxFaceHeight;
                coordSpan.innerText += `Current face height: ${dist}  Max face height: ${maxFaceHeight}\n`;

                // Status
                // ToDo: make these a %?
                // zLevel = Math.abs(top.z) <= 1 && Math.abs(bottom.z) <= 1;
                // xyLevel = Math.abs(top.x-bottom.x) <= 2;
                const pitchPct = Math.abs(top.z-bottom.z)/w <= sensitivity;
                const rollPct = Math.abs(top.x-bottom.x)/w <= sensitivity;

                // yaw calcs
                const centerToRightEar = Math.hypot(center.x-rightEar.x, center.y-rightEar.y);
                const centerToLeftEar =  Math.hypot(center.x-leftEar.x, center.y-leftEar.y);
                const yawPct = Math.abs(centerToRightEar-centerToLeftEar)/w <= sensitivity;

                // from center
                const centPct = (center.x - w/2)/w;
                if(Math.abs(centPct) < sensitivity)
                    fromCenter = "centered";
                else if (centPct < 0)
                    fromCenter = "⬅";
                else if (centPct > 0)
                    fromCenter = "➡";

                // from eyeLine
                const eyeLinePct = (center.y - h/3)/h;
                if(Math.abs(eyeLinePct) < sensitivity)
                    fromEyeLine = "good";
                else if (eyeLinePct < 0)
                    fromEyeLine = "⬇";
                else if (eyeLinePct > 0)
                    fromEyeLine = "⬆";

                // Figure out how to calc yaw

                statusSpan.innerText += `Pitch is ${pitchPct ? '': 'not '}level\n`;
                statusSpan.innerText += `Roll is ${rollPct ? '': 'not '}level\n`;
                statusSpan.innerText += `Yaw is ${yawPct ? '': 'not '}level\n`;
                statusSpan.innerText += `fromCenter: ${fromCenter}\n`;
                statusSpan.innerText += `fromEyeLine: ${fromEyeLine}\n`;

                /*
                statusSpan.innerText += `-------------------------------\n`;
                statusSpan.innerText += `center to rightEar: ${Math.hypot(center.x-rightEar.x, center.y-rightEar.y).toFixed(0)}\n`;
                statusSpan.innerText += `center to leftEar: ${Math.hypot(center.x-leftEar.x, center.y-leftEar.y).toFixed(0)}\n`;
                */

                // guidelines

                ctx.lineWidth = 3 * screen_multiplier;

                // top to bottom
                ctx.strokeStyle = 'rgba(0, 240, 0, 0.5)';
                ctx.beginPath();
                ctx.moveTo(top.x, top.y);
                ctx.lineTo(bottom.x, bottom.y);
                ctx.stroke();

                // left to right
                /*
                ctx.lineWidth = 1 * screen_multiplier;
                ctx.setLineDash([screen_multiplier, 1]);
                ctx.strokeStyle = 'rgba(0, 0, 240, 0.5)';
                ctx.beginPath();
                ctx.moveTo(right.x, right.y);
                ctx.lineTo(left.x, left.y);
                ctx.stroke();
                 */

                // left ear to right ear
                ctx.strokeStyle = 'rgba(0, 240, 0, 0.5)';
                ctx.beginPath();
                ctx.moveTo(leftEar.x, leftEar.y);
                ctx.lineTo(rightEar.x, rightEar.y);
                ctx.stroke();

                // drawConnectors(ctx, landmarks, FACEMESH_TESSELATION, {color: '#C0C0C070', lineWidth: 1});
                // drawConnectors(ctx, landmarks, FACEMESH_RIGHT_EYE, {color: '#FF3030'});
                // drawConnectors(ctx, landmarks, FACEMESH_RIGHT_EYEBROW, {color: '#FF3030'});
                // drawConnectors(ctx, landmarks, FACEMESH_RIGHT_IRIS, {color: '#FF3030'});
                // drawConnectors(ctx, landmarks, FACEMESH_LEFT_EYE, {color: '#30FF30'});
                // drawConnectors(ctx, landmarks, FACEMESH_LEFT_EYEBROW, {color: '#30FF30'});
                // drawConnectors(ctx, landmarks, FACEMESH_LEFT_IRIS, {color: '#30FF30'});
                // drawConnectors(ctx, landmarks, FACEMESH_FACE_OVAL, {color: '#E0E0E0'});
                // drawConnectors(ctx, landmarks, FACEMESH_LIPS, {color: '#E0E0E0'});

                drawConnectors(ctx, landmarks, FACEMESH_FACE_OVAL, {color: '#FFFDDD', lineWidth: 1});

                /*
                const [midwayBetweenEyes] = results.multiFaceLandmarks.annotations.midwayBetweenEyes
                const x = midwayBetweenEyes[0];
                const y = midwayBetweenEyes[1];
                ctx.strokeStyle = 'rgba(200, 0, 0, 0.5)';
                ctx.setLineDash([1, 1]);
                ctx.lineWidth = 3;
                ctx.beginPath();
                ctx.arc(x, y , 10, 0, 2*Math.PI)
                ctx.stroke();
                ctx.lineWidth = 1;
                ctx.setLineDash([]);
                 */

                /*
                for(const points in landmarks){
                    console.log(landmarks[points]);
                    const {x,y} = landmarks[points];
                    drawPoint(x,y);
                }

                drawPoint(0.5, 0.5);

                 */

                // crosshair
                ctx.lineWidth = 2*screen_multiplier;
                ctx.strokeStyle = 'rgba(200, 0, 0, 0.5)';
                ctx.setLineDash([screen_multiplier, screen_multiplier]);
                ctx.beginPath();
                ctx.moveTo(canvas.width / 2, 0);
                ctx.lineTo(canvas.width / 2, canvas.height);
                ctx.stroke();
                ctx.moveTo(0, canvas.height / 3);
                ctx.lineTo(canvas.width, canvas.height / 3);
                ctx.stroke();
                ctx.setLineDash([]);

            }
        }
        else{
            console.log("no face landmarks", results);
        }
        // ctx.restore();
    });


    async function start() {

        await getDevices();

        // Note: list of devices may change after first camera permission approval
        await getVideo();
    }

    deviceSelect.onchange = getVideo;

    await faceMesh.initialize();
    await start();

</script>
</body>
</html>
